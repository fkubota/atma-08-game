{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "- feature_developer_has 特徴量を作成する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = '020'\n",
    "\n",
    "PATH_TRAIN = './../data/official/train.csv'\n",
    "PATH_TEST = './../data/official/test.csv'\n",
    "PATH_SAMPLE_SUBMITTION = './../data/official/atmaCup8_sample-submission.csv'\n",
    "SAVE_DIR = f'../data/output_nb/nb{NB}/'\n",
    "\n",
    "feat_train_only = ['JP_Sales', 'Global_Sales', 'NA_Sales', 'Other_Sales', 'EU_Sales']\n",
    "feat_common = ['Name', 'Platform', 'Year_of_Release', 'Genre', 'Publisher',\n",
    "           'Critic_Score', 'Critic_Count', 'User_Score', 'User_Count', 'Developer',\n",
    "           'Rating']\n",
    "feat_string = ['Platform', 'Genre', 'Publisher', 'Rating']\n",
    "feat_cat = ['Platform', 'Genre', 'Rating']\n",
    "feat_num = ['Year_of_Release', 'Critic_Score', 'Critic_Count', 'User_Score', 'User_Count']\n",
    "use_col = [\n",
    "    'Platform',\n",
    "    'Year_of_Release',\n",
    "    'Genre',\n",
    "    'Critic_Score',\n",
    "    'Critic_Count',\n",
    "    'User_Score',\n",
    "    'User_Count',\n",
    "    'Rating'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_str = \"\"\"\n",
    "globals:\n",
    "  seed: 2020\n",
    "  show_log: True\n",
    "\n",
    "feature:\n",
    "    use_col: [\n",
    "        'Platform',\n",
    "        'Year_of_Release',\n",
    "        'Genre',\n",
    "        'Critic_Score',\n",
    "        'Critic_Count',\n",
    "        'User_Score',\n",
    "        'User_Count',\n",
    "        'Rating'\n",
    "        ]\n",
    "\n",
    "split:\n",
    "  name: KFold\n",
    "  params:\n",
    "    n_splits: 5\n",
    "    random_state: 2020\n",
    "    shuffle: True\n",
    "\n",
    "model:\n",
    "    model_params:\n",
    "        objective: 'regression'\n",
    "        metric: 'rmse'\n",
    "        n_estimators: 800\n",
    "        max_depth: 131\n",
    "        subsample: 0.6\n",
    "        colsample_bytree: 0.9\n",
    "        learning_rate: 0.022862256818781214\n",
    "        reg_alpha: 1.0\n",
    "        reg_lambda: 6.0\n",
    "        min_child_samples: 10\n",
    "    \n",
    "    train_params:\n",
    "        categorical_feature: ['Platform', 'Genre', 'Rating']\n",
    "        verbose: -1\n",
    "        early_stopping_rounds: 100\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import everything I need :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import yaml\n",
    "import types\n",
    "import builtins\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from fastprogress import progress_bar\n",
    "\n",
    "from lightgbm import LGBMRegressor \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noglobal\n",
    "\n",
    "def imports():\n",
    "    for name, val in globals().items():\n",
    "        # module imports\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            yield name, val\n",
    "\n",
    "            # functions / callables\n",
    "        if hasattr(val, '__call__'):\n",
    "            yield name, val\n",
    "\n",
    "\n",
    "def noglobal(f):\n",
    "    '''\n",
    "    ref: https://gist.github.com/raven38/4e4c3c7a179283c441f575d6e375510c\n",
    "    '''\n",
    "    return types.FunctionType(f.__code__,\n",
    "                              dict(imports()),\n",
    "                              f.__name__,\n",
    "                              f.__defaults__,\n",
    "                              f.__closure__\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal\n",
    "def metric(y_true, y_pred):\n",
    "    return mean_squared_log_error(y_true, y_pred) ** .5\n",
    "\n",
    "@noglobal\n",
    "def preprocess_User_Score(df):\n",
    "    '''\n",
    "    - tbdをnanにする\n",
    "    - stringをfloatにする\n",
    "    '''\n",
    "    mask = df.User_Score.values == 'tbd'\n",
    "    df.User_Score[mask] = np.nan\n",
    "    df.User_Score = df.User_Score.values.astype(float)\n",
    "    return df\n",
    "\n",
    "@noglobal\n",
    "def string_encode(df_trn, df_te, cols):\n",
    "    '''\n",
    "    - np.nanがあれば、'nan'に置き換える\n",
    "    - label encodingする\n",
    "    '''\n",
    "    df = pd.concat([df_trn, df_te], axis=0).copy()\n",
    "    df[cols] = df[cols].replace(np.nan, 'nan')\n",
    "    df_trn[cols] = df_trn[cols].replace(np.nan, 'nan')\n",
    "    df_te[cols] = df_te[cols].replace(np.nan, 'nan')\n",
    "    for col in cols:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(df[col])\n",
    "        df_trn[col] = le.transform(df_trn[col])\n",
    "        df_te[col] = le.transform(df_te[col])\n",
    "    return df_trn, df_te\n",
    "\n",
    "@noglobal\n",
    "def df_preprocessing(df_trn, df_te, string_cols):\n",
    "    df_trn = preprocess_User_Score(df_trn)\n",
    "    df_te = preprocess_User_Score(df_te)\n",
    "    df_trn, df_te = string_encode(df_trn, df_te, string_cols)\n",
    "    return df_trn, df_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal\n",
    "def run_fold_lgbm(_X_trn, _y_trn, _X_val, _y_val, _X_te, model_config, show_log=True):\n",
    "    model_params = model_config['model_params']\n",
    "    train_params = model_config['train_params']\n",
    "    \n",
    "    # train\n",
    "    model = LGBMRegressor(**model_params)\n",
    "    model.fit(_X_trn, _y_trn.values[:, 0],\n",
    "              eval_set=[(_X_trn, _y_trn), (_X_val, _y_val)],\n",
    "              **train_params\n",
    "             )\n",
    "    \n",
    "    # predict\n",
    "    y_trn_pred = model.predict(_X_trn)\n",
    "    y_val_pred = model.predict(_X_val)\n",
    "    _y_test_pred = model.predict(_X_te)\n",
    "    \n",
    "    # postprocessiing\n",
    "    y_trn_pred[y_trn_pred <= 1] = 1\n",
    "    y_val_pred[y_val_pred <= 1] = 1\n",
    "    y_trn_pred = np.expm1(y_trn_pred)  # exp を適用して 1 を引く\n",
    "    y_val_pred = np.expm1(y_val_pred)  # exp を適用して 1 を引く\n",
    "    _y_test_pred = np.expm1(_y_test_pred)  # exp を適用して 1 を引く\n",
    "    \n",
    "    if show_log:\n",
    "        print(show_log)\n",
    "        print(f'score train: {metric(np.expm1(_y_trn), y_trn_pred):.5f}')\n",
    "        print(f'score valid: {metric(np.expm1(_y_val), y_val_pred):.5f}')\n",
    "        print('')\n",
    "    \n",
    "    return y_trn_pred, y_val_pred, _y_test_pred\n",
    "\n",
    "@noglobal\n",
    "def run_lgbm(X, y, X_te, splitter, config):\n",
    "    show_log = config['globals']['show_log']\n",
    "    model_config = config['model']\n",
    "\n",
    "    oof = np.zeros(len(X))\n",
    "    y_test_pred = np.zeros(len(X_te))\n",
    "    for fold_i, (idx_trn, idx_val) in enumerate(splitter.split(X)):\n",
    "        if show_log:\n",
    "            print(f'::Fold {fold_i+1}/{splitter.n_splits} start at {time.ctime()}::')\n",
    "        X_trn, X_val = X.iloc[idx_trn, :], X.iloc[idx_val, :]\n",
    "        y_trn, y_val = y.iloc[idx_trn], y.iloc[idx_val]\n",
    "        X_trn = pd.DataFrame(X_trn, columns=X.columns)\n",
    "        X_val = pd.DataFrame(X_val, columns=X.columns)\n",
    "\n",
    "        # train\n",
    "        y_trn_pred, y_val_pred, _y_test_pred = run_fold_lgbm(X_trn, y_trn, X_val, y_val, \n",
    "                                                             X_te, model_config, \n",
    "                                                             show_log=show_log)\n",
    "\n",
    "        # result\n",
    "        oof[idx_val] = y_val_pred\n",
    "        y_test_pred += _y_test_pred / splitter.n_splits\n",
    "\n",
    "\n",
    "    y_test_pred[y_test_pred <= 1] = 1\n",
    "    return oof, y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(SAVE_DIR):\n",
    "    os.makedirs(SAVE_DIR)\n",
    "\n",
    "config = yaml.safe_load(config_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(PATH_TRAIN)\n",
    "test = pd.read_csv(PATH_TEST)\n",
    "ss = pd.read_csv(PATH_SAMPLE_SUBMITTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df_preprocessing(train, test, feat_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[use_col].copy()\n",
    "y = train[['Global_Sales']].copy()\n",
    "X_te = test[use_col].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSLE を RMSEとしいて解く\n",
    "y = np.log1p(y)  # 1 を足してlog を適用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "textを小文字にして1行に"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Developer'] = train['Developer'].replace(np.nan, 'nan')\n",
    "test['Developer'] = test['Developer'].replace(np.nan, 'nan')\n",
    "\n",
    "train_word_line = ' '.join(train.Developer.str.lower().values)\n",
    "test_word_line = ' '.join(test.Developer.str.lower().values)\n",
    "\n",
    "train_word_list = train_word_line.split(None)\n",
    "test_word_list = test_word_line.split(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traveller's tales traveller's tales traveller's tales nan traveller's tales traveller's tales ryu ga gotoku studios traveller's tales snowblind studios snowblind studios amaze entertainment traveller's tales shiny entertainment nan nan high moon studios traveller's tales high moon studios shiny entertainment crystal dynamics, nixxes software nan traveller's tales nan traveller's tales traveller's tales nan wayforward nan grasshopper manufacture nan skonec altron high voltage software nan nan pendulo studios capcom snk playmore harmonix music systems nan culture brain rare ltd. nan nan atomic p\n",
      "\n",
      "io interactive crystal dynamics kcej double helix games double helix games nan nan vicarious visions blue tongue entertainment nan nan visceral games incognito inc. artificial mind and movement radical entertainment namco bandai games america, namco bandai games telltale games nan nan nan techland konami nan nan nan handheld games vicious cycle lucky chicken konami computer entertainment hawaii darkworks wxp wxp 1st playable productions nan nan nan nan aki corp. nan digital fiction nan pipeworks software, inc. panic button nan nan nan harmonix music systems harmonix music systems harmonix musi\n"
     ]
    }
   ],
   "source": [
    "print(train_word_line[:600])\n",
    "print('')\n",
    "print(test_word_line[:600])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "trainとtest共通のワードを取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['&',\n",
       " '7',\n",
       " 'america,',\n",
       " 'bluepoint',\n",
       " 'furyu',\n",
       " 'saffire',\n",
       " 'arcade',\n",
       " 'cyberconnect2',\n",
       " 'and',\n",
       " 'games',\n",
       " 'eclipse',\n",
       " 's.r.l',\n",
       " '4a',\n",
       " 'remedy',\n",
       " 'assembly',\n",
       " 'magic',\n",
       " 'torus',\n",
       " 'conspiracy',\n",
       " 'irem',\n",
       " 'crytek']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_word_unique = list(set(train_word_list) & set(test_word_list))\n",
    "common_word_unique[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "testで数える"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='648' class='' max='648' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [648/648 00:21<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.5 s, sys: 23.8 ms, total: 21.5 s\n",
      "Wall time: 21.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "common_words_in_test = []\n",
    "for word in progress_bar(common_word_unique):\n",
    "    bools = []\n",
    "    for dev in test.Developer.values:\n",
    "        words = np.array(str(dev).split(None))\n",
    "        bool_ = any(words == word)\n",
    "        bools.append(bool_)\n",
    "        \n",
    "        if bool_:\n",
    "            common_words_in_test.append(word)\n",
    "            \n",
    "\n",
    "# test_has_word = pd.DataFrame()\n",
    "# for text in progress_bar(texts):\n",
    "#     bools = []\n",
    "#     for name in test.Name.str.lower().values:\n",
    "#         words = np.array(str(name).split(None))\n",
    "#         bools.append(any(words == text))\n",
    "#     test_has_word[f'Name_has_{text}'] = bools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "testの中の数を見る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan         3134\n",
       "of            42\n",
       "and           27\n",
       "7             10\n",
       "17            10\n",
       "44             7\n",
       "1st            6\n",
       "id             5\n",
       "&              4\n",
       "5pb            4\n",
       "h.a.n.d.       3\n",
       "13             3\n",
       "3              2\n",
       "989            1\n",
       "505            1\n",
       "dtp            1\n",
       "5              1\n",
       "1              1\n",
       "10tacle        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_counts = pd.Series(common_words_in_test).value_counts(ascending=False)\n",
    "value_counts[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---> 全然使えないじゃん。  \n",
    "---> ボツ"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
